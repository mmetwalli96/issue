#include <cstdio>
#include <iostream>
#include <filesystem>
#include "torch/torch.h"
#include "torch/script.h"

int main()
{
    // set the device as CPU

    // load the accuracy model
    const std::string model_path = "../model.pt";
    torch::jit::script::Module model = torch::jit::load(model_path, c10::kCPU);

    std::cout << "the model has been loaded\n";

    std::vector<float> input_vector = {0.006916589103639126,0.006981133949011564,0.006981185637414455,0.0008322549983859062,4.5955927951979447e-10,0.000011755926607293077,2.511088281753615e-10,
    0.000005274142040434526,1.4461959407796598e-10,0.0000029959549010527553,1.9951196250644898e-10,0.000001925502374433563,2.272547566795069e-10,0.0000013360688626562478,
    7.257450751474437e-10,9.7563543022261e-7,9.718711391215606e-10,0.020140592008829117,0.020735524594783783,0.02092207968235016,0.0068391310051083565,0.0004306164337322116,
    0.00013003815547563136,0.0001589518942637369,0.00010926349204964936,0.00012649693235289305,0.00005027751103625633,0.00006648575799772516,0.000036623019695980474,
    0.000041382932977285236,0.000016275071175186895,0.000017185027900268324,0.00001681811045273207,0.000027265001335763372,0.032297708094120026,0.034312065690755844,
    0.037560753524303436,0.013982022181153297,0.0028582264203578234,0.0005443050758913159,0.00039729641866870224,0.0003875133115798235,0.00022328365594148636,
    0.00015425955643877387,0.00014865584671497345,0.00013791507808491588,0.0002577846171334386,0.0000641525475657545,0.00008894331404007971,0.000049396567192161456,
    0.000091829955636058,0.044149599969387054,0.04844491928815842,0.0569792166352272,0.01811540126800537,0.007383710239082575,0.0010732164373621345,0.0015240631764754653,
    0.0006829779595136642,0.0004847724922001362,0.0005354013410396874,0.0002094504307024181,0.0002506439050193876,0.00025086948880925775,0.00013496249448508024,
    0.000221521346247755,0.0001608092279639095,0.00013619038509204984,0.05603751540184021,0.06321614980697632,0.07524801790714264,0.021590331569314003,
    0.013429741375148296,0.0046514784917235374,0.003531991969794035,0.0013952908338978887,0.0010283977026119828,0.0011205131886526942,0.0003085458592977375,0.0005996617255732417,
    0.0003462191380094737,0.0004676491371355951,0.0002300840278621763,0.0002620463783387095,0.00021469732746481895,0.06800748407840729,0.07844389975070953,
    0.08961130678653717,0.024414412677288055,0.020793432369828224,0.010030983947217464,0.005730347242206335,0.0025576711632311344,0.002117927884683013,
    0.0011872254544869065,0.0011837665224447846,0.0010760041186586022,0.0006281976238824427,0.0006498133880086243,0.0003229990543331951,0.0004804627096746117,
    0.0003555378061719239,0.07751933485269547,0.09376902133226395,0.09893468022346497,0.026137961074709892,0.02883889712393284,0.016479510813951492,0.008559164591133595,
    0.004387162625789642,0.0035787674132734537,0.0015103903133422136,0.0022084079682826996,0.0012277938658371568,0.0008961427374742925,0.0009746899013407528,0.0007627459708601236,
    0.0008111082715913653,0.00047896927571855485,0.07914842665195465,0.1069740429520607,0.10839755088090897,0.026719314977526665,0.0346035398542881,0.022254053503274918,
    0.01315630879253149,0.0068104080855846405,0.005239146761596203,0.0026879010256379843,0.0028400614392012358,0.0013663049321621656,0.0015779235400259495,0.0011869914596900344,
    0.0009344758000224829,0.0010707629844546318,0.0005545350140891969,0.07065534591674805,0.11740943789482117,0.12181515991687775,0.025518188253045082,0.03529715538024902,
    0.02736341394484043,0.01940365508198738,0.009775142185389996,0.0072557064704597,0.004564163275063038,0.003567596897482872,0.002024611458182335,0.0020892613101750612,
    0.0014206619234755635,0.0013971426524221897,0.0010332901729270816,0.000896352285053581,0.05561314895749092,0.12673945724964142,0.1344020515680313,0.022230811417102814,
    0.03150338679552078,0.03218473494052887,0.024750567972660065,0.013168375939130783,0.00939103402197361,0.005901696160435677,0.004132006783038378,0.002935812110081315,
    0.0023464669939130545,0.0016869236715137959,0.0018944618059322238,0.0012194268638268113,0.0012492811074480414,0.03802996873855591,0.13304324448108673,0.14715346693992615,
    0.017491990700364113,0.024909602478146553,0.03647038713097572,0.02726099267601967,0.016607284545898438,0.011763852089643478,0.006607447285205126,0.0045080529525876045,
    0.004093511961400509,0.003024000907316804,0.0024313509929925203,0.0023024578113108873,0.0017494683852419257,0.0018273881869390607,0.02127717062830925,0.13377387821674347,
    0.16082578897476196,0.013498482294380665,0.019764287397265434,0.04032851755619049,0.02642536349594593,0.021054252982139587,0.013616029173135757,0.007541613187640905,
    0.005689100828021765,0.006164462771266699,0.004290132317692041,0.0047911847941577435,0.0029463758692145348,0.0029526574071496725,0.0024334753397852182,0.00816539116203785,
    0.12654583156108856,0.174870565533638,0.012290207669138908,0.020177466794848442,0.043599262833595276,0.023290423676371574,0.026427948847413063,0.015154799446463585,
    0.010078907012939453,0.00805697776377201,0.007961480878293514,0.005709159653633833,0.007041181903332472,0.003963032271713018,0.004008751828223467,0.002727738581597805,
    -0.0009975265711545944,0.1125025749206543,0.18600280582904816,0.012855993583798409,0.0221088919788599,0.04736476019024849,0.020524591207504272,0.029822492972016335,
    0.017058245837688446,0.012828797101974487,0.010269262827932835,0.008762827143073082,0.007147850468754768,0.008867555297911167,0.005068112630397081,0.005611066240817308,
    0.003235297044739127,-0.007173366844654083,0.09420298039913177,0.1928752064704895,0.01357454713433981,0.022672293707728386,0.05321713909506798,0.018261050805449486,
    0.03079362027347088,0.017392370849847794,0.016565289348363876,0.010652327910065651,0.009350686334073544,0.008680946193635464,0.009721299633383751,0.006758563686162233,
    0.006696611642837524,0.004110157489776611,-0.011148728430271149,0.0753084123134613,0.19363795220851898,0.013259160332381725,0.02107473649084568,0.06016312167048454,
    0.015058718621730804,0.030851006507873535,0.01569484733045101,0.0211463812738657,0.010564742609858513,0.010144941508769989,0.010054313577711582,0.009564475156366825,
    0.00843572523444891,0.00791550800204277,0.005240050610154867,-0.01420917920768261,0.0595133900642395,0.18974877893924713,0.011284413747489452,0.017119072377681732,
    0.06812115013599396,0.010942671447992325,0.03184669464826584,0.013061311095952988,0.025751307606697083,0.01015083771198988,0.010888626798987389,0.011055837385356426,
    0.009282705374062061,0.010115372017025948,0.009132884442806244,0.007112747058272362,-0.016461936756968498,0.046178705990314484,0.18286719918251038,0.008164812810719013,
    0.011096242815256119,0.07430874556303024,0.006608631461858749,0.033878393471241,0.010510941036045551,0.026936860755085945,0.008586574345827103,0.00990996602922678,
    0.011338949203491211,0.008885339833796024,0.012318124063313007,0.009905503131449223,0.009558513760566711,-0.017811007797718048,0.03448677435517311,0.17422454059123993,
    0.005078338086605072,0.005894730798900127,0.0780496895313263,0.005667935125529766,0.036954134702682495,0.009517264552414417,0.025594325736165047,0.009066790342330933,
    0.009439199231564999,0.011950062587857246,0.009637379087507725,0.013569842092692852,0.010286522097885609,0.011284845881164074,-0.01807425171136856,0.023881904780864716,
    0.16371457278728485,0.0033081250730901957,0.006292664911597967,0.07981979846954346,0.00884825736284256,0.039710063487291336,0.01082083024084568,0.022735178470611572,
    0.011871222406625748,0.009734134189784527,0.012847158126533031,0.011050829663872719,0.014517154544591904,0.010921815410256386,0.013110441155731678,-0.017554128542542458,
    0.014458324760198593,0.1524900197982788,0.003619945840910077,0.009832487441599369,0.08153431862592697,0.01201367937028408,0.04274683818221092,0.01276931818574667,
    0.020665904507040977,0.014224778860807419,0.010854227468371391,0.013016817159950733,0.011787202209234238,0.014851103536784649,0.011130808852612972,0.014150133356451988,
    -0.016509126871824265,0.006809603422880173,0.1413518190383911,0.0049138120375573635,0.013586008921265602,0.08318603783845901,0.015511429868638515,0.04520908370614052,
    0.015159155242145061,0.020650794729590416,0.015946239233016968,0.011958103626966476,0.013136508874595165,0.01178796123713255,0.014745849184691906,0.010386486537754536,
    0.014321508817374706,-0.015346463769674301,0.0007958970963954926,0.13234032690525055,0.006155717186629772,0.01700986735522747,0.08567998558282852,0.019564343616366386,
    0.04752640053629875,0.017748763784766197,0.02110736072063446,0.0167411956936121,0.012305675074458122,0.01360404584556818,0.011553092859685421,0.014206008985638618,
    0.009392596781253815,0.013498526997864246,-0.014236371964216232,-0.003529101610183716,0.12543408572673798,0.0067526800557971,0.018909350037574768,0.08839075267314911,
    0.022523608058691025,0.05043657124042511,0.019894100725650787,0.021665751934051514,0.017011607065796852,0.01220829226076603,0.014087975956499577,0.011941682547330856,
    0.014221804216504097,0.009690937586128712,0.013459826819598675,-0.013263186439871788,-0.006531212478876114,0.11957713961601257,0.006921230349689722,0.01994405873119831,
    0.09065556526184082,0.024953853338956833,0.05391695350408554,0.021747292950749397,0.022331535816192627,0.016362100839614868,0.011437473818659782,0.013714230619370937,
    0.012813897803425789,0.014697076752781868,0.011145534925162792,0.01396756898611784,-0.012501278892159462,-0.008409449830651283,0.11497832834720612,0.007058529183268547,
    0.020938562229275703,0.09219785034656525,0.027236351743340492,0.05755923315882683,0.02354617230594158,0.02405652590095997,0.015829993411898613,0.010410463437438011,
    0.013279293663799763,0.013105837628245354,0.015234765596687794,0.012143537402153015,0.014589836820960045,-0.011851008981466293,-0.009456668049097061,0.11022806167602539,
    0.007156332954764366,0.02163093164563179,0.09239397943019867,0.02885155938565731,0.060833822935819626,0.025108525529503822,0.026952901855111122,0.015784740447998047,
    0.008597118780016899,0.01232570968568325,0.01154707744717598,0.014764307998120785,0.011880774050951004,0.014206714928150177,-0.011339567601680756,-0.010081997141242027,
    0.10614335536956787,0.007502708118408918,0.02295290306210518,0.09224943816661835,0.03120427392423153,0.06398387998342514,0.027635347098112106,0.030835533514618874,
    0.016956454142928123,0.007965882308781147,0.011391578242182732,0.008585203438997269,0.013942397199571133,0.010801201686263084,0.013696827925741673,-0.0111997090280056,
    -0.010060673579573631,0.10202793776988983,0.007778108585625887,0.024022553116083145,0.09140939265489578,0.033229727298021317,0.06667692214250565,0.030203107744455338,
    0.035564322024583817,0.01896193064749241,0.01141277700662613,0.011229835450649261,0.005283496808260679,0.01331672165542841,0.009216029196977615,0.013544276356697083,
    -0.011178184300661087,-0.009439405053853989,0.09706185758113861,0.008108026348054409,0.02519982121884823,0.08872836083173752,0.03527722880244255,0.06717763841152191,
    0.0327078253030777,0.038983993232250214,0.021114440634846687,0.0162058025598526,0.011764362454414368,0.005118685774505138,0.013021053746342659,0.007181541528552771,
    0.013490023091435432,-0.01075834035873413,-0.008540570735931396,0.08960892260074615,0.008115986362099648,0.025390366092324257,0.08321448415517807,0.036038655787706375,
    0.06503346562385559,0.03425711393356323,0.040676962584257126,0.023065313696861267,0.020658785477280617,0.012518142350018024,0.008817627094686031,0.012197228148579597,
    0.0056455545127391815,0.01292252354323864,-0.009722021408379078,-0.007337712682783604,0.07847942411899567,0.007660028524696827,0.024119462817907333,0.07369242608547211,
    0.03475208953022957,0.0589560903608799,0.03390796482563019,0.03905893862247467,0.023826725780963898,0.02284013107419014,0.013094046153128147,0.012529032304883003,
    0.011553090997040272,0.00680514145642519,0.01279403641819954, 2, 1, 1, 3};

    // create the input tensor
    float *features = new float[548];
    std::copy(input_vector.begin(), input_vector.end(), features);

    at::Tensor tensor = torch::from_blob(features, {1, 548});

    delete[] features;

    torch::jit::Stack stack;
    torch::jit::push(stack, tensor);

    // execute the model
    at::Tensor score_tensor = model.forward(stack).toTensor();
    float score = score_tensor.item().toFloat();

    // print the score
    std::cout << "the score is: " << score << "\n";


    return 0;
}